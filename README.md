# Multi-arm-Bandit
resources of multi-arm bandit

### The features of a multi-arm bandit problem:
* (F1) only one machine is operated at each time instant. The evolution of the machine that is being operated is uncontrolled; that is, the processor chooses which machine to operate but not how to operate it;
* (F2) machines that are not operated remain frozen; 
* (F3) machines are independent;
* (F4) frozen machines contribute no reward.

### Algorithms:
* Epsilon-Greedy
* UCB
* Contextual Bandits
  * LinUCB
  * CoLin
  * hLinUCB
  * FactorUCB
* Thompson Sampling (Bayesian)
  * Bernoulli, Binomial <=> Beta Distributions

### Books and Book Chapters
* [Reinforcement Learning: An Introduction](https://webdocs.cs.ualberta.ca/~sutton/book/the-book.html)
* [Multi-armed Bandit Allocation Indices](http://www.wiley.com/WileyCDA/WileyTitle/productCd-0470670029.html)
* [Bandit Algorithms for Website Optimization](http://shop.oreilly.com/product/0636920027393.do)
* [Multi-Armed Bandit Problems (in Foundations and Applications of Sensor Management)](http://web.eecs.umich.edu/~teneket/pubs/MAB-Survey.pdf)

### Academic Articles
* [Latent Contextual Bandits and Their Application to Personalized Recommendations for New Users](https://www.ijcai.org/Proceedings/16/Papers/513.pdf)
* [A Survey on Contextual Multi-armed Bandits](http://arxiv.org/abs/1508.03326)
* [Contextual Bandits in A Collaborative Environment(SIGIR'2016)]()
* [Learning Hidden Features for Contextual Bandits. (CIKM 2016)]()
* [Factorization Bandits for Interactive Recommendation.(AAAI 2017)]()
* [Returning is Believing: Optimizing Long-term User Engagement in Recommender Systems.(CIKM 2017)]()
* [Portfolio Choices with Orthogonal Bandit Learning-IJCAI 2015] (http://yugangjiang.info/publication/ijcai15-OBL.pdf)

### Blog Posts
* [When to Run Bandit Tests Instead of A/B/n Tests](https://conversionxl.com/bandit-tests/)
* [Bandit theory, part I](https://blogs.princeton.edu/imabandit/2016/05/11/bandit-theory-part-i/)
* [Bandit theory, part II](https://blogs.princeton.edu/imabandit/2016/05/13/bandit-theory-part-ii/)
* [Bandits for Recommendation Systems](http://engineering.richrelevance.com/bandits-recommendation-systems/)
* [Recommendations with Thompson Sampling](http://engineering.richrelevance.com/recommendations-thompson-sampling/)
* [Personalization with Contextual Bandits](http://engineering.richrelevance.com/personalization-contextual-bandits/)
* [Bayesian Bandits - optimizing click throughs with statistics](https://www.chrisstucchio.com/blog/2013/bayesian_bandit.html)
* [Mulit-Armed Bandits](https://dataorigami.net/blogs/napkin-folding/79031811-multi-armed-bandits)
* [Bayesian Bandits](http://tdunning.blogspot.de/2012/02/bayesian-bandits.html)
* [Python Multi-armed Bandits (and Beer!)](http://blog.yhat.com/posts/the-beer-bandit.html)

### Presentations
* [Boston Bayesians Meetup 2016 - Bayesian Bandits From Scratch](https://sites.google.com/site/simplebayes/home/boston-bayesians)
* [ODSC East 2016 - Bayesian Bandits](https://goo.gl/TJt8sG)
* [NYC ML Meetup 2010 - Learning for Contextual Bandits](http://hunch.net/~exploration_learning/main.pdf)

### scholars
- [David S. Leslie-Lancaster University](https://scholar.google.co.uk/citations?user=ev_o35QAAAAJ&hl=en)
- [B. Van Roy-Stanford University](https://web.stanford.edu/~bvr/)
- [RÃ©mi Munos-Deepmind](https://scholar.google.com.hk/citations?user=OvKEnVwAAAAJ&hl=zh-CN&oi=ao)
- [Csaba Szepesvari-Deepmind/Alberta University](https://scholar.google.com.hk/citations?user=zvC19mQAAAAJ&hl=zh-CN)
- [Emma Brunskill-Stanford University](https://scholar.google.com/citations?user=HaN8b2YAAAAJ&hl=en&oi=sra)
